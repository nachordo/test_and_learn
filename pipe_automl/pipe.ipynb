{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator  # Base class for all estimators in scikit-learn.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "class BestClassifier(BaseEstimator):\n",
    "\n",
    "    def __init__(self,X,y, models=[\"LogisticRegression\", \"LinearSVC\",\"SGDClassifier\",\n",
    "                             \"KNeighborsClassifier\",\"GaussianNB\",\"RandomForestClassifier\"]):\n",
    "        \"\"\"\n",
    "        A Custome BaseEstimator that chooses the best model and the best hyperparameters for a dataset\n",
    "        \"\"\"\n",
    "        self.models = models\n",
    "        self.parameters = {}\n",
    "        self.parameters['LogisticRegression']={\"penalty\":[\"l1\",\"l2\"],\"C\":np.logspace(-4,2,10)}\n",
    "        self.parameters['LinearSVC']={\"C\":np.logspace(-4,2,10), \"penalty\":[\"l1\", \"l2\"]}\n",
    "        self.parameters['SGDClassifier']={\"penalty\":[\"elasticnet\"],\"alpha\":np.logspace(-4,2,10), \"l1_ratio\":np.linspace(0,1,10)} \n",
    "        self.parameters['KNeighborsClassifier']={\"n_neighbors\":[1,2,4,5,10.15,20],\n",
    "                                                 \"metric\":[\"euclidean\",\"minkowski\",\"manhattan\",\"chebyshev\"]}\n",
    "        self.parameters['GaussianNB']={'var_smoothing': np.logspace(0,-9, num=20)}\n",
    "        self.parameters['RandomForestClassifier']={'n_estimators': [5,10,25],\n",
    "                                                   'max_features': ['auto', 'sqrt', 'log2'],\n",
    "                                                   'min_samples_split':[2,5,10,20,30],\n",
    "                                                   'max_depth' : [None,5,10,25,50,100,250,500],\n",
    "                                                   'criterion' :['gini', 'entropy']}\n",
    "        self.decide(X,y)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def grid(self,  X, y,classifier_type: str = 'LogisticRegression'):\n",
    "        if classifier_type == 'LogisticRegression':\n",
    "            self.classifier_ = LogisticRegression(max_iter=5000)\n",
    "            search=GridSearchCV(LogisticRegression(max_iter=5000) , self.parameters['LogisticRegression'],\n",
    "                                n_jobs=-1, cv=5,verbose=0)\n",
    "            search.fit(X, y)\n",
    "            self.classifier_ = LogisticRegression(max_iter=5000,**search.best_params_)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "        elif classifier_type == 'LinearSVC':\n",
    "            self.classifier_ = LinearSVC(max_iter=5000)\n",
    "            search=GridSearchCV(self.classifier_ , self.parameters['LinearSVC'], n_jobs=-1, cv=5,verbose=0)\n",
    "            search.fit(X, y)\n",
    "            self.classifier_ = LinearSVC(max_iter=5000,**search.best_params_)\n",
    "\n",
    "            \n",
    "            \n",
    "        elif classifier_type == 'SGDClassifier':\n",
    "            self.classifier_ = SGDClassifier(max_iter=5000)\n",
    "            search=GridSearchCV(self.classifier_ , self.parameters['SGDClassifier'], n_jobs=-1, cv=5,verbose=0)\n",
    "            search.fit(X, y)\n",
    "            self.classifier_ = SGDClassifier(max_iter=5000,**search.best_params_)\n",
    "\n",
    "            \n",
    "            \n",
    "        elif classifier_type == 'KNeighborsClassifier':\n",
    "            self.classifier_ = KNeighborsClassifier()\n",
    "            search=GridSearchCV(self.classifier_ , self.parameters['KNeighborsClassifier'], n_jobs=-1, cv=5,verbose=0)\n",
    "            search.fit(X, y)\n",
    "            self.classifier_ = KNeighborsClassifier(**search.best_params_)\n",
    "\n",
    "            \n",
    "            \n",
    "        elif classifier_type == 'GaussianNB':\n",
    "            self.classifier_ = GaussianNB()\n",
    "            search=GridSearchCV(self.classifier_ , self.parameters['GaussianNB'], n_jobs=-1, cv=5,verbose=0)\n",
    "            search.fit(X, y)\n",
    "            self.classifier_ = GaussianNB(**search.best_params_)\n",
    "\n",
    "            \n",
    "            \n",
    "        elif classifier_type == 'RandomForestClassifier':\n",
    "            self.classifier_ = RandomForestClassifier()\n",
    "            search=GridSearchCV(self.classifier_ , self.parameters['RandomForestClassifier'], n_jobs=-1, cv=5,verbose=0)\n",
    "            search.fit(X, y)\n",
    "            self.classifier_ = RandomForestClassifier(**search.best_params_)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            raise ValueError('Unkown classifier type.')\n",
    "\n",
    "        \n",
    "        return self.classifier_.fit(X, y),search.best_score_\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def decide(self,X,y):\n",
    "        \n",
    "        score=0\n",
    "        for model in self.models:\n",
    "            clf,score_t=self.grid(X, y,model)\n",
    "            if score < score_t:\n",
    "                score=score_t\n",
    "                print(\"New one:\"+model)\n",
    "                self.bestclassifier_=clf\n",
    "        \n",
    "        \n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self.bestclassifier_.fit(X, y)\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        return self.bestclassifier_.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.bestclassifier_.predict_proba(X)\n",
    "\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return self.bestclassifier_.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "X, y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\datascience\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.71333333        nan 0.72              nan 0.78666667\n",
      "        nan 0.86              nan 0.93333333        nan 0.96\n",
      "        nan 0.97333333        nan 0.97333333        nan 0.98\n",
      "        nan 0.98      ]\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\envs\\datascience\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.34666667        nan 0.66666667        nan 0.66666667\n",
      "        nan 0.73333333        nan 0.94              nan 0.95333333\n",
      "        nan 0.96666667        nan 0.96666667        nan 0.97333333\n",
      "        nan 0.96666667]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New one:LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\datascience\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "D:\\anaconda3\\envs\\datascience\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New one:SGDClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\datascience\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.96       0.94666667 0.97333333 0.97333333        nan 0.96\n",
      " 0.96       0.94666667 0.97333333 0.97333333        nan 0.96\n",
      " 0.96       0.93333333 0.95333333 0.96              nan 0.97333333\n",
      " 0.96       0.96       0.97333333 0.98666667        nan 0.92666667]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf=BestClassifier(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.01, l1_ratio=0.8888888888888888, max_iter=5000,\n",
       "              penalty='elasticnet')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.bestclassifier_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
